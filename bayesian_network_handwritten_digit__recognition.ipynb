{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwRTWPyy0CAfGCWPGNmgMp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kylewon0102/bayesian_network_handwritten_digit_recognition/blob/main/bayesian_network_handwritten_digit__recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sys"
      ],
      "metadata": {
        "id": "igVGGZZxVWG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "data load and normalizing\n",
        "\"\"\"\n",
        "\n",
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalize the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_APAA6NO4ak",
        "outputId": "690fdfb8-8e18-4bb3-874b-34edf7059573"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "model build\n",
        "input 784 normalized pixels\n",
        "hidden 128 neurons with relu activation + drop certain percentage of neurons\n",
        "output 10 digits\n",
        "\"\"\"\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)), #input layer of 784 inputs\n",
        "    tf.keras.layers.Dense(128, activation='relu'), #hidden layer of 128 neurons using relu algorithm to check if these neurons get activated i.e. over .5\n",
        "    tf.keras.layers.Dropout(0.2), #dropping percentage of neurons during training to prevent overfitting\n",
        "    tf.keras.layers.Dense(10, activation='softmax') #output layer of 10 outputs (number 0 ~ 9)\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_L5JONh2U2N0",
        "outputId": "32fdbc6a-9a56-44a5-f632-bd796deab6fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Models with different batchs\n",
        "\"\"\"\n",
        "\n",
        "def compile_batch(alpha):\n",
        "  # Compile the model with adam (a combination between adaGrad and Momentum)\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = alpha),\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  # Train the model\n",
        "  model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "def compile_mini_batch(alpha, size):\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = alpha),\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  # Train the model\n",
        "  model.fit(x_train, y_train, epochs=5, batch_size=size)\n",
        "\n",
        "\n",
        "def compile_stochastic(alpha): #just using SGD optimizer as we are doing SGD\n",
        "  model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate = alpha),\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  model.fit(x_train, y_train, epochs=5, batch_size=1)"
      ],
      "metadata": {
        "id": "uhbM9H6gVSLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Evaluating and display\n",
        "\"\"\"\n",
        "def main():\n",
        "  sys.stdout.write(\"Models Available\" + '\\n' + \"1. Batch\" + '\\n' + \"2. Mini Batch\" + '\\n' + \"3. Stochastic\" + '\\n')\n",
        "  model_choice = int(input(\"Use \"))\n",
        "  alpha = 0.001\n",
        "\n",
        "  if model_choice == 1:\n",
        "    compile_batch(alpha)\n",
        "  elif model_choice == 2:\n",
        "    compile_mini_batch(alpha, 64)\n",
        "  elif model_choice == 3:\n",
        "    compile_stochastic(alpha)\n",
        "\n",
        "def test():\n",
        "  # Evaluate the model\n",
        "  test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "  print(f\"Test accuracy: {test_acc}\")\n",
        "\n",
        "  # Make predictions\n",
        "  predictions = model.predict(x_test)\n",
        "\n",
        "  fig, axes = plt.subplots(1, 5, figsize=(12, 3))\n",
        "  # Display first 5 images with predictions\n",
        "\n",
        "  for i, ax in enumerate(axes):\n",
        "    ax.imshow(x_test[i], cmap=plt.cm.binary)\n",
        "    ax.set_title(f\"Prediction: {np.argmax(predictions[i])}\")\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "3wNpxXBxV49r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QVvWkK4lKVQs",
        "outputId": "886d91bb-6287-40fb-9db7-812ecf704e32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models Available\n",
            "1. Batch\n",
            "2. Mini Batch\n",
            "3. Stochastic\n",
            "Use 1\n",
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 6ms/step - accuracy: 0.8577 - loss: 0.4835\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - accuracy: 0.9558 - loss: 0.1500\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9662 - loss: 0.1122\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9733 - loss: 0.0872\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9778 - loss: 0.0716\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "id": "ulCqkaqPMJGj",
        "outputId": "69e0ea63-0823-453d-dcc9-3018b3d517a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9727 - loss: 0.0963\n",
            "Test accuracy: 0.9768999814987183\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x300 with 5 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7YAAADKCAYAAACR8ty/AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAHoVJREFUeJzt3Xl4zWf+//F3EkEWeyJCJUjGzliC0aqtBBEuazFGcXVaYmKpa9DJ+NKiKBlDjcvWa6QzuKxVS4Oi9LKUMFK1Vpuxji0IWkQk+fz+yC+p+NyHc07Okjt5Pq4rf3id+9yfd+L+5OR9Pufcx8MwDEMAAAAAANCUp7sLAAAAAACgIGhsAQAAAABao7EFAAAAAGiNxhYAAAAAoDUaWwAAAACA1mhsAQAAAABao7EFAAAAAGiNxhYAAAAAoDUaWwAAAACA1mhsX6JGjRoybNiwvH/v27dPPDw8ZN++fQ47hoeHh3zwwQcOmw9wFNY/ijvOARRnrH8Ud5wDeinUjW1CQoJ4eHjkfZUuXVpq164tsbGxcvPmTXeXZ5PExERtFu2zP/Pnvzp37uzu8ooN1r/rZWdnS0JCgvTs2VOqV68ufn5+0rBhQ5kxY4akp6e7u7xih3PAPZKSkmTUqFHSvHlz8fb2Fg8PD3eXVCyx/t3n7Nmz0rVrV/H395eKFSvKkCFDJDU11d1lFTucA+739OlTqV+/vnh4eEh8fLy7y3mpEu4uwBrTpk2TmjVrSnp6uhw4cEAWL14siYmJcurUKfH19XVpLW3btpXHjx9LyZIlbbpfYmKiLFq0SLmoHz9+LCVKFJ7/in//+9+m7NixY7JgwQKJjIx0Q0XFG+vfdR49eiTDhw+X3/3udzJy5EipXLmyfPvttzJ16lTZs2ePfP311/yR7wacA66VmJgon376qTRu3Fhq1aol58+fd3dJxRrr37WuXr0qbdu2lXLlysnMmTPll19+kfj4eDl58qQkJSXZ/L2j4DgH3GfhwoVy+fJld5dhtcL5U3xOt27dJCIiQkRE/vjHP0qlSpVk3rx5snnzZhk0aJDyPg8fPhQ/Pz+H1+Lp6SmlS5d26JyOnq+g/vCHP5iy3JdeWPp5w3lY/65TsmRJOXjwoLz66qt52TvvvCM1atTIa247derkxgqLJ84B14qJiZFJkyaJj4+PxMbG0ti6GevftWbOnCkPHz6U//znPxISEiIiIi1btpTOnTtLQkKCvPvuu26usPjhHHCPW7duybRp02TSpEkyZcoUd5djlUL9UmRLOnbsKCIiFy5cEBGRYcOGib+/v6SkpEhUVJSUKVNGBg8eLCI5Ly2cP3++NGjQQEqXLi1BQUEyYsQISUtLyzenYRgyY8YMeeWVV8TX11c6dOggp0+fNh3b0mvrjxw5IlFRUVKhQgXx8/OTxo0by4IFC/LqW7RokYjkf5lvLtVr65OTk6Vbt25StmxZ8ff3lzfeeEMOHz6cb0zuSzQOHjwo48ePl8DAQPHz85PevXubXjJz//59OXfunNy/f9+aH3E+T548kY0bN0q7du3klVdesfn+cCzWfw5nrP+SJUvma2pz9e7dW0RyXp4G9+McyOGsx4CgoCDx8fF56Ti4B+s/h7PW/8aNGyU6OjqvqRUR6dSpk9SuXVvWrVv30vvD+TgHcji7D3j//felTp06ygtehZUWV2yfl5KSIiIilSpVyssyMzOlS5cu0qZNG4mPj897acKIESMkISFBhg8fLmPGjJELFy7IP/7xD0lOTpaDBw+Kt7e3iIhMmTJFZsyYIVFRURIVFSXHjx+XyMhIycjIeGk9u3btkujoaAkODpaxY8dKlSpV5OzZs7Jt2zYZO3asjBgxQq5duya7du1Svsz3eadPn5bXX39dypYtKxMnThRvb29ZunSptG/fXr755htp1apVvvGjR4+WChUqyNSpU+XixYsyf/58iY2NlbVr1+aN2bRpkwwfPlxWrFiR703w1khMTJR79+7l/ZKAe7H+Xbv+RURu3LghIiIBAQE23xeOxzng+nMAhQfr33nr/3//+5/cunUr7+rgs1q2bCmJiYkvrR/Oxzng/MeApKQk+eyzz+TAgQN6vQXLKMRWrFhhiIixe/duIzU11bhy5YqxZs0ao1KlSoaPj49x9epVwzAMY+jQoYaIGO+//36+++/fv98QEWPVqlX58h07duTLb926ZZQsWdLo3r27kZ2dnTcuLi7OEBFj6NChednevXsNETH27t1rGIZhZGZmGjVr1jRCQ0ONtLS0fMd5dq4//elPhqUft4gYU6dOzft3r169jJIlSxopKSl52bVr14wyZcoYbdu2Nf18OnXqlO9Y7733nuHl5WXcu3fPNHbFihXKGl6kb9++RqlSpUzfH5yL9V841r9hGEanTp2MsmXLcg64GOeA+8+BF9UN52L9u379Hz161BAR41//+pfptgkTJhgiYqSnp79wDjgO54B7HgOys7ONli1bGoMGDTIMwzAuXLhgiIgxd+7cl97X3bR4KXKnTp0kMDBQqlevLgMHDhR/f3/ZtGmTVKtWLd+4mJiYfP9ev369lCtXTjp37iy3b9/O+2revLn4+/vL3r17RURk9+7dkpGRIaNHj873rMS4ceNeWltycrJcuHBBxo0bJ+XLl893mz3PcGRlZclXX30lvXr1klq1auXlwcHB8vvf/14OHDggDx48yHefd999N9+xXn/9dcnKypJLly7lZcOGDRPDMGx+pv7Bgwfy5ZdfSlRUlOn7g2uw/t23/kVy3m+1e/dumT17NueAm3AOuPccgHux/l23/h8/fiwiIqVKlTLdlvs+yNwxcB3OAdc+BiQkJMjJkyfl448/trl+d9PipciLFi2S2rVrS4kSJSQoKEjq1Kkjnp75e/ISJUqY3v/5448/yv3796Vy5crKeW/duiUikvcf/5vf/Cbf7YGBgVKhQoUX1pb7coiGDRta/w29QGpqqjx69Ejq1Kljuq1evXqSnZ0tV65ckQYNGuTlz74PRETyan7+/QP22Lhxo6Snp/MyZDdi/edwx/pfu3atTJ48Wd5++23TAyZch3MghzvOAbgf6z+HK9Z/7nvLnzx5Yrot9yPfeP+563EO5HDFOfDgwQP5y1/+IhMmTJDq1avbfH9306KxbdmypfL9Ds8qVaqUaZFnZ2dL5cqVZdWqVcr7BAYGOqxGd/Ly8lLmhmEUeO5Vq1ZJuXLlJDo6usBzwT6s/xdz1vrftWuXvPXWW9K9e3dZsmRJgeZCwXAOvJgzHwPgfqz/F3Pk+g8ODhYRkevXr5tuu379ulSsWFF5NRfOxTnwYo48B+Lj4yUjI0MGDBggFy9eFJGcj8ASyWmUL168KFWrVi20H3ulRWNrr7CwMNm9e7e89tprL3yGLTQ0VERyntl59rJ/amrqS5/tCAsLExGRU6dOvfBjQKx9OUJgYKD4+vrKDz/8YLrt3Llz4unp6bJnUK5fvy579+6VYcOG8YtcQ6x/+x05ckR69+4tERERsm7dukL7+XJ4Mc4BFGesf9tVq1ZNAgMD5dixY6bbkpKSpEmTJk47NhyPc8B2ly9flrS0tHxXhHPNnDlTZs6cKcnJyYX2XNDiPbb2evPNNyUrK0umT59uui0zM1Pu3bsnIjmv3ff29paFCxfme3Zj/vz5Lz1Gs2bNpGbNmjJ//vy8+XI9O1fuZ2k9P+Z5Xl5eEhkZKZs3b857pkRE5ObNm7J69Wpp06aNlC1b9qV1Pc+ebb7XrFkj2dnZvAxZU6z/X9my/s+ePSvdu3eXGjVqyLZt23jZmcY4B35VkI98g55Y/7+yZf337dtXtm3bJleuXMnL9uzZI+fPn5f+/fvbfGy4D+fAr6w9B8aMGSObNm3K97V06VIRyXmf7qZNm6RmzZo2H99VivRliHbt2smIESNk1qxZ8t1330lkZKR4e3vLjz/+KOvXr5cFCxZIv379JDAwUP785z/LrFmzJDo6WqKioiQ5OVm2b9/+0o/38PT0lMWLF0uPHj2kSZMmMnz4cAkODpZz587J6dOnZefOnSIi0rx5cxHJWTBdunQRLy8vGThwoHLOGTNmyK5du6RNmzYyatQoKVGihCxdulSePHkic+bMsetnYc9HPaxatUqqVq0q7du3t+uYcC/W/6+sXf8///yzdOnSRdLS0mTChAny5Zdf5rs9LCxMWrdubVcNcD3OgV/Z8hhw6dKlvI+kyL1yNWPGDBHJubIxZMgQu2qAa7H+f2XL+o+Li5P169dLhw4dZOzYsfLLL7/I3LlzpVGjRjJ8+HC7jg/34Bz4lbXnQLNmzaRZs2b5stwGu0GDBtKrVy+7ju8yrt2E2Ta5W1MfPXr0heOGDh1q+Pn5Wbx92bJlRvPmzQ0fHx+jTJkyRqNGjYyJEyca165dyxuTlZVlfPjhh0ZwcLDh4+NjtG/f3jh16pQRGhr6wm2+cx04cMDo3LmzUaZMGcPPz89o3LixsXDhwrzbMzMzjdGjRxuBgYGGh4dHvi2/5bltvg3DMI4fP2506dLF8Pf3N3x9fY0OHToYhw4dsurno6rR1o96OHfunCEixvjx460aD8dj/bt+/eduaW/p69mfBZyPc8A9jwG591d9tWvX7qX3h2Ow/t33N9CpU6eMyMhIw9fX1yhfvrwxePBg48aNG1bdF47DOeC+c+BZOn3cj4dhsLsEAAAAAEBfRfo9tgAAAACAoo/GFgAAAACgNRpbAAAAAIDWaGwBAAAAAFqjsQUAAAAAaI3GFgAAAACgNRpbAAAAAIDWaGwBAAAAAFqjsQUAAAAAaI3GFgAAAACgNRpbAAAAAIDWaGwBAAAAAFqjsQUAAAAAaI3GFgAAAACgNRpbAAAAAIDWaGwBAAAAAFqjsQUAAAAAaI3GFgAAAACgNRpbAAAAAIDWaGwBAAAAAFqjsQUAAAAAaI3GFgAAAACgNRpbAAAAAIDWSri7AACFQ3x8vDJ//PixMv/++++V+YYNG6w+ZkxMjDJv3bq1Mh8yZIjVcwMAAKD44IotAAAAAEBrNLYAAAAAAK3R2AIAAAAAtEZjCwAAAADQGo0tAAAAAEBrHoZhGO4uAoBrDRgwwJStX7/eDZWohYeHK/Pdu3ebspCQEGeXA7jc+fPnlXmdOnVM2SeffKIcO3r0aIfWBDzr4cOHynzChAmmbMmSJcqxERERytzS41FoaKiV1QEojrhiCwAAAADQGo0tAAAAAEBrNLYAAAAAAK3R2AIAAAAAtEZjCwAAAADQWgl3FwDAeVS7H4s4ZgfkunXrKvOuXbuasv/+97/KsVu2bFHmP/30kzJfuXKlKYuLi7NUIqCt5ORkZe7paX4+ulq1as4uBzC5du2aMl++fLkp8/LyUo49duyYMt+6dasyj42NtbI6wHbHjx9X5n369FHmFy9edGI1BffVV18p83r16inz6tWrO7Mcl+CKLQAAAABAazS2AAAAAACt0dgCAAAAALRGYwsAAAAA0BqbRwFFgKUNODZt2mT1HA0bNlTmljZ4CggIUOb+/v6mLCMjQzm2VatWyvzEiRPK/M6dO8ocKGq+++47Za46vyxtbAI4QmpqqjIfOnSoiysBnGvnzp3K/MmTJy6uxDEs/f32z3/+U5mvWbPGmeW4BFdsAQAAAABao7EFAAAAAGiNxhYAAAAAoDUaWwAAAACA1mhsAQAAAABa025X5A0bNijz5cuXK/OqVasq89KlS5uywYMHK8dWqVJFmYeHhytzwNWuX7+uzA3DUOaqHZAt7QYYHBxsf2H/X3x8vDI/e/asTfNER0cXuBagMDl58qQyX7hwoTJ/6623nFkOirFPPvlEmX/xxRfK/OjRo06rZf/+/cpc9Zj229/+Vjm2bdu2Dq0JRUtmZqYpS0xMdEMlzhMREaHM582bp8wfPnxoyvz8/Bxak7NxxRYAAAAAoDUaWwAAAACA1mhsAQAAAABao7EFAAAAAGiNxhYAAAAAoDXtdkWeMGGCMr948WKB516yZIkyL1u2rDKvX79+gY/pDtWrV1fmEydONGWWdlRD4dKjRw9l/tNPPynzMmXKmLKKFSs6tKZnrV27VplnZGQ47ZiADn744QdlrtqdUkRkwIABziwHxdi4ceOUuZeXl2sLEZHPP//c6jwkJEQ5dt26dcq8efPm9heGImPv3r2m7NChQ8qxkyZNcnY5TnH37l1lfvr0aWX+6NEjU8auyAAAAAAAuBCNLQAAAABAazS2AAAAAACt0dgCAAAAALRGYwsAAAAA0Jp2uyJ/+umnyvzEiRPK3NLOxWfOnDFlycnJyrH79u1T5ocPH1bmqh36Ll++rBxrK29vb1MWEBCgHHv9+nVlbqlu1W7J7Iqst9DQUJcfc+7cuabs/PnzNs3RqlUrm3JAV3PmzFHmNWrUUOb8ToYjREVFmTLDMJRjs7KynFaHpb9fLO3EeunSJVN24cIF5dgWLVoo8+zsbCurQ1Fw8uRJZT5w4EBTFh4erhwbFxfn0JpcZcuWLe4uweW4YgsAAAAA0BqNLQAAAABAazS2AAAAAACt0dgCAAAAALSm3eZRb7zxhk25JV27drV6bFpamjK3tNmUanOPo0ePWn28FylVqpQpq1OnjnJs3bp1lfndu3eVeVhYmP2FodjZtm2bMp8yZYope/LkiXJsUFCQMp89e7Yy9/X1tbI6oHC5ePGiMrf02GDp97qlTXUAlW+++UaZnzt3zpR5eHgox3p5eRW4jpEjRyrzyMhIZV6uXDll/vXXX5uyjz76yKZaFi9erMxjYmJsmgd6sLQ+Hj16ZMpWrlypHOvv7+/QmhzN0t/1ls5/S+d6UcAVWwAAAACA1mhsAQAAAABao7EFAAAAAGiNxhYAAAAAoDUaWwAAAACA1rTbFdkdKlSooMw7duxo9Ry27tpsi40bNypzS7s5N27cWJkPHDjQYTWh6Dt27Jgyt7QDssqAAQOUebt27eyqCSisLO1OaUlgYKCTKkFRZGnXbUuP67dv3y7wMUNCQpR5v379TNnUqVOVY23d6T40NNSULV26VDnW0vc4ceJEZZ6enm7KYmNjlWO9vb0tlQg32bBhgzJPTExU5uHh4aasRYsWDq3JVWbMmKHMLe1+3L59e2Vevnx5B1XkPlyxBQAAAABojcYWAAAAAKA1GlsAAAAAgNZobAEAAAAAWqOxBQAAAABojV2RNXPr1i1TNmrUKOVYwzCU+ZQpU5R5xYoV7S8MRVavXr2U+c6dO62eY+jQocrc0k5+QFHz/fff2zTe0s6tgMrTp0+VuSN2P27btq0yX7t2rTIPCAgo8DEtUe2KHBcXpxw7fvx4Zf7w4UNlrjrnevbsqRwbFhZmqUS4yfr165W5pf/vmJgYZ5bjNKod0FevXq0cW6KEus2bPHmyMi8Ku31zxRYAAAAAoDUaWwAAAACA1mhsAQAAAABao7EFAAAAAGiNxhYAAAAAoDV2RdbMokWLTJlqp2QRkfLlyyvzOnXqOLIkFBHXr19X5ocOHVLmT548UeaBgYGmzNIOfP7+/lZWB+jj22+/NWUrVqxQjm3atKky79y5s0NrAl6mRYsWytzS2nXm7se2sLRz8apVq5R5UlKSM8uBk92/f1+ZHz582KZ5LH2iSGG3bNkyU5aamqocW79+fWXesWNHh9ZUmHDFFgAAAACgNRpbAAAAAIDWaGwBAAAAAFqjsQUAAAAAaI3NowqpAwcOKPPZs2dbPcfmzZuVecOGDe2qCUVbnz59lPnt27dtmmfw4MGmLCwszK6aAB3t2bPHlKWlpSnHdu3aVZmXLl3aoTWheMrKyrJ67JEjR5xYifMYhqHMs7OzbRqv+llNnTpVOXblypVWVgdHs7Rx5dWrV5X5oEGDnFmOy6WkpFg9tjj+vc8VWwAAAACA1mhsAQAAAABao7EFAAAAAGiNxhYAAAAAoDUaWwAAAACA1tgVuZBKTExU5hkZGaasU6dOyrGtW7d2aE0oOrZs2WLKkpOTbZqjffv2ynzatGn2lAQUGSdOnLB6bP/+/Z1YCYqLJUuWKHMvLy8XV+J6W7duVeaWHtM8PDyUuepn9eGHH9pfGJyiTJkyyrxJkybK/OTJk8r87t27pqxixYp21+Vot27dUubr16+3eo7XXnvNUeVogyu2AAAAAACt0dgCAAAAALRGYwsAAAAA0BqNLQAAAABAazS2AAAAAACtsSuymz1+/FiZ79ixQ5mXKlXKlFnatc/b29v+wlAk3LlzR5nPnDnTlKl23H4RSzsQ+vv72zQPoKsbN24o8/3795uyunXrKsf27t3boTWheNq2bZu7S3Co1NRUZX7mzBlTpno8s0dAQIAp4++owsfHx0eZh4eHK/MNGzYo8+7du5uy8ePH21/YS5w6dUqZp6SkKPNLly4pc0u7eqt4eha/65fF7zsGAAAAABQpNLYAAAAAAK3R2AIAAAAAtEZjCwAAAADQGo0tAAAAAEBr7IrsZnPnzlXmycnJyrxbt26m7NVXX3VoTSg6/va3vynzpKQkq+fo1auXMp82bZo9JQFFRkJCgjK/efOmKVP97gag9tFHHynzRYsWFXjuGjVqKPPPPvvMlIWEhBT4eHCNDz74QJkbhqHMVTuJDxw40JEl5RMYGKjMLe1yfPv27QIfc/jw4QWeQzdcsQUAAAAAaI3GFgAAAACgNRpbAAAAAIDWaGwBAAAAAFpj8ygXUb1JXURk+vTpyrxcuXLK/P/+7/8cVhOKvnnz5hV4Dkubdfj7+xd4bkBnly5dsnpshQoVnFgJoKeoqChlfu7cOacds379+sr89ddfd9ox4Xz16tVT5uvWrVPmqk1aU1JSHFrTs/r162fT+KFDhyrzlStXWj2Hj4+PTccsCrhiCwAAAADQGo0tAAAAAEBrNLYAAAAAAK3R2AIAAAAAtEZjCwAAAADQGrsiO8GdO3dM2ZgxY5RjMzMzlbmlnQJbt25tf2GAHVTrWUTE29vbace0tCu46phPnz5Vjr1//75Nx0xLSzNlf//7322awxIvLy9T9vHHHyvH+vr6OuSYcL6tW7daPTY6OtqJlaC4MwxDmWdlZVk9x/bt22065jvvvKPMr127ZvUclur28PCwqRZbWPqUChQvTZs2tSpzl1q1ahV4jpMnTyrzRo0aFXjuwoortgAAAAAArdHYAgAAAAC0RmMLAAAAANAajS0AAAAAQGs0tgAAAAAArbErcgFY2m2wa9eupuzChQvKseHh4cp8+vTp9hcGOFDjxo1dfsw333xTmQcHB5uymzdvKseuWbPGoTU5WlBQkDKfPHmyiyvBy+zfv1+ZW1p7gKvFxMQo84kTJ1o9R/fu3ZW5alf3F7FlvKW/o2w9psrIkSMLPAfgLpZ2DLeUqxTl3Y8t4YotAAAAAEBrNLYAAAAAAK3R2AIAAAAAtEZjCwAAAADQGo0tAAAAAEBr7IpcACkpKcr82LFjVs8xb948ZR4WFmZXTcCzoqKilPkXX3zh2kJstG7dOqfN7e3trcw9Pa1/nq9nz57KPCIiwuo52rRpY/VYuNemTZuUeWZmpjJv2rSpKWvXrp1DawKe1adPH2U+Z84cZX779m1nllNgAQEByrxevXqmbPny5cqxql30AV14eHjYlCMHV2wBAAAAAFqjsQUAAAAAaI3GFgAAAACgNRpbAAAAAIDW2DzKCpcuXVLmkZGRVs8RHx+vzKOjo+2qCbDG559/rsxVG4pkZGQ45JhnzpwxZWvWrHHI3G+//bYpCw0NtWmOvn37KnPVpiQoXh49eqTMt2/fbtM8/fv3N2VeXl521QRYw9LvwbVr1ypz1QaC8+fPd2BFBfPXv/5VmcfGxrq4EsA90tPTrR7r4+PjxEr0whVbAAAAAIDWaGwBAAAAAFqjsQUAAAAAaI3GFgAAAACgNRpbAAAAAIDWPAzDMNxdRGEXFxenzGfNmmX1HEePHlXmERERdtUEAHCsp0+fKvO2bdsq86CgIGW+evVqU+br62t/YYAL7NixQ5kvW7ZMmW/dulWZ9+jRw5SNGDFCOdbSn6D169dX5iEhIcocKGqqVKmizFWPU1OmTFGOHTt2rENr0gFXbAEAAAAAWqOxBQAAAABojcYWAAAAAKA1GlsAAAAAgNZobAEAAAAAWmNX5Gfs379fmXfv3l2Z//zzz1bPza7IAAAAAF5Gtbu4iMh7771nyjp27OjscrTBFVsAAAAAgNZobAEAAAAAWqOxBQAAAABojcYWAAAAAKA1GlsAAAAAgNZKuLuAwuTAgQPK3Jbdj0VEwsPDTZm/v79dNQEAAAAoPrZu3eruErTEFVsAAAAAgNZobAEAAAAAWqOxBQAAAABojcYWAAAAAKA1No8qgCZNmijzPXv2mLKKFSs6uRoAAAAAKJ64YgsAAAAA0BqNLQAAAABAazS2AAAAAACt0dgCAAAAALRGYwsAAAAA0JqHYRiGu4sAAAAAAMBeXLEFAAAAAGiNxhYAAAAAoDUaWwAAAACA1mhsAQAAAABao7EFAAAAAGiNxhYAAAAAoDUaWwAAAACA1mhsAQAAAABao7EFAAAAAGiNxhYAAAAAoDUaWwAAAACA1mhsAQAAAABao7EFAAAAAGiNxhYAAAAAoDUaWwAAAACA1v4fra7dwBpwwz8AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (For Future Project) Write the above code in Hand"
      ],
      "metadata": {
        "id": "kXd6vGYpyrP3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "w_1 a_1 - w_2 a_2 + w_3 a_3 +w_4 a_4 + ... + w_n a_n\n",
        "\n",
        "sigmoid:\n",
        "δ(x) = 1/(1+e^(-x))\n",
        "\n",
        "bias\n",
        "only activate neuron when weighted sum > 10\n",
        "\n",
        "δ(w_1 a_1 + w_2 a_2 + w_3 a_3 + ... + w_n a_n - 10)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "28 x 28 low rs handwritten digits\n",
        "\n",
        "each pixel (total 786 pixels) have each 0 to 255 values assigned to show whether its black or white\n",
        "\n",
        "neural network:\n",
        "0. input layer 784 nodes\n",
        "1. hidden layer 10 nodes\n",
        "2. output layr 10 nodes\n",
        "\n",
        "forward propagation\n",
        "- A_0 = x\n",
        "- z_1 = w_1 dot A_0 + b_1\n",
        "- A_1 = g(Z_1) = ReLu(Z_1)\n",
        "\n",
        "rectified linear unit\n",
        "| x if x > 0  |\n",
        "| 0 if x <= 0 |\n",
        "\n",
        "Softmax activation function\n",
        "\n",
        "\n",
        "Back propagation\n",
        "- dz_2 = A_2 - Y\n",
        "- dw_2 = 1/m dz_2 A_1T"
      ],
      "metadata": {
        "id": "3ZoaHtJiBtvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Reshape data to fit the neural network\n",
        "x_train = x_train.reshape(x_train.shape[0], -1).T  # Shape (784, 60000)\n",
        "x_test = x_test.reshape(x_test.shape[0], -1).T\n",
        "\n",
        "# Initialize parameters\n",
        "def init_params():\n",
        "    w1 = np.random.rand(10, 784) - 0.5\n",
        "    b1 = np.random.rand(10, 1) - 0.5\n",
        "    w2 = np.random.rand(10, 10) - 0.5\n",
        "    b2 = np.random.rand(10, 1) - 0.5\n",
        "    w3 = np.random.rand(10, 10) - 0.5\n",
        "    b3 = np.random.rand(10, 1) - 0.5\n",
        "    return w1, b1, w2, b2, w3, b3\n",
        "\n",
        "# Activation and utility functions\n",
        "def ReLU(val):\n",
        "    return np.maximum(val, 0)\n",
        "\n",
        "def softmax(Z):\n",
        "    exp = np.exp(Z - np.max(Z)) # Prevent overflow\n",
        "    return exp / exp.sum(axis=0)\n",
        "\n",
        "def forward_prop(w1, b1, w2, b2, w3, b3, x):\n",
        "    raw1 = w1.dot(x) + b1\n",
        "    active1 = ReLU(raw1)\n",
        "    raw2 = w2.dot(active1) + b2\n",
        "    active2 = ReLU(raw2)\n",
        "    raw3 = w3.dot(active2) + b3\n",
        "    active3 = softmax(raw3)\n",
        "    return raw1, active1, raw2, active2, raw3, active3\n",
        "\n",
        "def d_Relu(val):\n",
        "    return val > 0\n",
        "\n",
        "def one_hot(Y):\n",
        "    one_hot_Y = np.zeros((Y.max()+1,Y.size))\n",
        "    one_hot_Y[Y,np.arange(Y.size)] = 1\n",
        "    return one_hot_Y\n",
        "\n",
        "def backward_prop(X, Y, A1, A2, A3, W2, W3, Z1, Z2, m):\n",
        "    one_hot_Y = one_hot(Y)\n",
        "    dZ3 = 2*(A3 - one_hot_Y)\n",
        "    dW3 = 1/m * (dZ3.dot(A2.T))\n",
        "    db3 = 1/m * np.sum(dZ3,1)\n",
        "    dZ2 = W3.T.dot(dZ3)*d_Relu(Z2)\n",
        "    dW2 = 1/m * (dZ2.dot(A1.T))\n",
        "    db2 = 1/m * np.sum(dZ2,1)\n",
        "    dZ1 = W2.T.dot(dZ2)*d_Relu(Z1)\n",
        "    dW1 = 1/m * (dZ1.dot(X.T))\n",
        "    db1 = 1/m * np.sum(dZ1,1)\n",
        "    return dW1, db1, dW2, db2, dW3, db3\n",
        "\n",
        "def update_params(w1, b1, w2, b2, w3, b3, dw1, db1, dw2, db2, dw3, db3, alpha):\n",
        "    w1 -= alpha * dw1\n",
        "    b1 -= alpha * db1.reshape(-1, 1)  # Ensure db1 is column vector of shape (10, 1)\n",
        "    w2 -= alpha * dw2\n",
        "    b2 -= alpha * db2.reshape(-1, 1)  # Ensure db2 is column vector of shape (10, 1)\n",
        "    w3 -= alpha * dw3\n",
        "    b3 -= alpha * db3.reshape(-1, 1)  # Ensure db3 is column vector of shape (10, 1)\n",
        "    return w1, b1, w2, b2, w3, b3\n",
        "\n",
        "\n",
        "def get_predictions(val):\n",
        "    return np.argmax(val, 0)\n",
        "\n",
        "def get_accuracy(predictions, Y):\n",
        "    return np.sum(predictions == Y) / Y.size\n",
        "\n",
        "def gradient_descent(x, y, alpha, iterations):\n",
        "    size, m = x.shape\n",
        "    w1, b1, w2, b2, w3, b3 = init_params()\n",
        "    for i in range(iterations):\n",
        "        r1, a1, r2, a2, r3, a3 = forward_prop(w1, b1, w2, b2, w3, b3, x)\n",
        "        dw1, db1, dw2, db2, dw3, db3 = backward_prop(x, y, a1, a2, a3, w2, w3, r1, r2, m)\n",
        "        w1, b1, w2, b2, w3, b3 = update_params(w1, b1, w2, b2, w3, b3, dw1, db1, dw2, db2, dw3, db3, alpha)\n",
        "        if i % 10 == 0:\n",
        "            predictions = get_predictions(a3)\n",
        "            print(f\"Iteration: {i}, Accuracy: {get_accuracy(predictions, y)}\")\n",
        "    return w1, b1, w2, b2, w3, b3\n",
        "\n",
        "# Set parameters and run gradient descent\n",
        "alpha = 0.01  # Learning rate\n",
        "iterations = 100  # Number of iterations\n",
        "w1, b1, w2, b2, w3, b3 = gradient_descent(x_train, y_train, alpha, iterations)\n"
      ],
      "metadata": {
        "id": "m5mxdYfJDXx2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "300181c5-0bd7-40fc-8725-b8d9a301d5b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-8173c53419ea>:28: RuntimeWarning: invalid value encountered in divide\n",
            "  return exp / exp.sum(axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 0, Accuracy: 0.09496666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the test set\n",
        "predictions = get_predictions(forward_prop(w1, b1, w2, b2, w3, b3, x_test)[5])\n",
        "\n",
        "# Visualize some test images and the predicted labels\n",
        "for i in range(5):\n",
        "    plt.imshow(x_test[:, i].reshape(28, 28), cmap='gray')\n",
        "    plt.title(f\"Predicted: {predictions[i]}, Actual: {y_test[i]}\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "pMfEfUwNLg_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.kaggle.com/code/wwsalmon/simple-mnist-nn-from-scratch-numpy-no-tf-keras/comments"
      ],
      "metadata": {
        "id": "mcHRrA-WRN3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fruits = [1, 2, 3]\n",
        "print(fruits[-1])"
      ],
      "metadata": {
        "id": "Fc-fsulznB5P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}